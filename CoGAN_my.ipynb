{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoGAN_my.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBZSOBmt_BqR",
        "colab_type": "code",
        "outputId": "22b6f044-aef0-406e-b966-66ae94ccbbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn3nLiVJuUhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f670ca7a-f3fd-455a-bf71-9f7987bc93ef"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "os.chdir('drive/My Drive/PPT/')\n",
        "!pwd\n",
        "!unzip mnist_train.csv.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PPT\n",
            "Archive:  mnist_train.csv.zip\n",
            "  inflating: mnist_train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdgzYhGv2YS",
        "colab_type": "code",
        "outputId": "433633b4-ebba-48fb-9daf-a990f3ba4138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "device = get_default_device()\n",
        "print(device)\n",
        "\n",
        "def to_device(data,device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x,device) for x in data]\n",
        "    else:\n",
        "        return data.to(device, non_blocking=True)\n",
        "    \n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDFfILKhwMxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('mnist_train.csv')\n",
        "target = df_train['label']\n",
        "df_train.drop('label', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhR0PLp8waaj",
        "colab_type": "code",
        "outputId": "a2449b28-0aae-4d20-a010-2cd2714fcbe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(df_train, target, stratify=target, random_state=42, test_size=0.020)\n",
        "print('X_train ', X_train.shape)\n",
        "print('X_dev ', X_dev.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train  (58800, 784)\n",
            "X_dev  (1200, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCEG_D8m3sxC",
        "colab_type": "code",
        "outputId": "ff09130d-a412-40e1-d13b-056494370484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torchvision\n",
        "print('PIL',torchvision.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PIL 0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozE9_itEwwHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torchvision.transforms.functional as TF\n",
        "class CharData(Dataset):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 images,\n",
        "                 labels=None,\n",
        "                 transform=None,\n",
        "                ):\n",
        "        self.X = images\n",
        "        self.y = labels\n",
        "        \n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx2 = int(idx/2)+1#np.random.randint(0, self.__len__(), 1)\n",
        "        idx3 = int(idx/3)+1\n",
        "        img1 = np.array(self.X.iloc[idx, :], dtype='uint8').reshape([28, 28, 1])\n",
        "        img2 = np.array(self.X.iloc[idx2, :], dtype='uint8').reshape([28, 28, 1])\n",
        "        img3 = np.array(self.X.iloc[idx3, :], dtype='uint8').reshape([28, 28, 1])\n",
        "\n",
        "        # img1[img1>0] = 255\n",
        "        # img2[img2>0] = 255\n",
        "        img3 = 255 - img3\n",
        "\n",
        "        transform1 = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize([0], [0.5])\n",
        "        ])\n",
        "        transform2 = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomRotation(degrees=(89,90), fill=(0,)),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize([0], [0.5])\n",
        "        ])\n",
        "#         average = img.sum() / (28*28)\n",
        "#         img1 = np.ones((28,28,1), dtype='uint8') * int(average)\n",
        "#         img1 = np.flip(img,1)\n",
        "#         img = np.concatenate((img, img1), axis=2)\n",
        "\n",
        "        \n",
        "        img1 = transform1(img1)\n",
        "        img2 = transform2(img2)\n",
        "        img3 = transform1(img3)\n",
        "        # img1.where(img1>0,1,0)\n",
        "        # img2.where(img2>0,1,0)\n",
        "        \n",
        "        # if self.y is not None:\n",
        "        #     y = np.zeros(10, dtype='float32')\n",
        "        #     y[self.y.iloc[idx]] = 1\n",
        "        #     return img, y\n",
        "        # else:\n",
        "        return img1, img2, img3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUWiBT7ByXHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = CharData(X_train, y_train)#, train_transform)\n",
        "dev_dataset = CharData(X_dev, y_dev)#, transform=test_transform)\n",
        "# test_dataset = CharData(X_test, transform=test_transform)\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "dev_loader = DataLoader(dataset=dev_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "dev_loader = DeviceDataLoader(dev_loader, device)\n",
        "# test_loader = DeviceDataLoader(test_loader, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyj8lOVcLbaS",
        "colab_type": "code",
        "outputId": "16d30f9b-59ee-4721-e6cb-dd7ed826a1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "for batch_idx, (x1, x2, x3) in enumerate(train_loader):\n",
        "    fig=plt.figure(figsize=(2, 2))\n",
        "    fig.add_subplot(2, 2, 1)\n",
        "    plt.imshow(x1.cpu().numpy()[2,0,:,:])\n",
        "    fig.add_subplot(2, 2, 2)\n",
        "    plt.imshow(x2.cpu().numpy()[2,0,:,:])\n",
        "    fig.add_subplot(2, 2, 3)\n",
        "    plt.imshow(x3.cpu().numpy()[2,0,:,:])\n",
        "\n",
        "    break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 144x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ASjz8PC_mkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__() \n",
        "\n",
        "        n1,n2,n3,n4 = 64,128,256,512#256,512,1024,1500\n",
        "\n",
        "        self.fc1 = nn.Linear(g_input_dim, n1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(n1)\n",
        "        self.fc2 = nn.Linear(n1, n2)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(n2)\n",
        "        self.fc3 = nn.Linear(n2, n3)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(n3)\n",
        "        self.fc4 = nn.Linear(n3, n4)\n",
        "        self.batchnorm4 = nn.BatchNorm1d(n4)\n",
        "        self.fc51 = nn.Linear(n4, g_output_dim)\n",
        "        self.fc52 = nn.Linear(n4, g_output_dim)\n",
        "        self.fc53 = nn.Linear(n4, g_output_dim)\n",
        "    \n",
        "    def forward(self, x): \n",
        "        x = F.leaky_relu(self.batchnorm1(self.fc1(x)))\n",
        "        x = F.leaky_relu(self.batchnorm2(self.fc2(x)))\n",
        "        x = F.leaky_relu(self.batchnorm3(self.fc3(x)))\n",
        "        x = F.leaky_relu(self.batchnorm4(self.fc4(x)))\n",
        "        x1 = torch.sigmoid(self.fc51(x))\n",
        "        x2 = torch.sigmoid(self.fc52(x))\n",
        "        x3 = torch.sigmoid(self.fc53(x))\n",
        "        return x1.view(x1.size(0),1,28,28), x2.view(x2.size(0),1,28,28), x3.view(x3.size(0),1,28,28)\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        n1,n2,n3 = 32,64,256#32,64,256\n",
        "\n",
        "        self.conv11 = nn.Conv2d(1,n1,5)\n",
        "        self.conv12 = nn.Conv2d(1,n1,5)\n",
        "        self.conv13 = nn.Conv2d(1,n1,5)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(n1,n2,5)\n",
        "        self.conv22 = nn.Conv2d(n1,n2,5)\n",
        "        self.conv23 = nn.Conv2d(n1,n2,5)\n",
        "\n",
        "        # self.fc11 = nn.Linear(16*n2,n3)\n",
        "        # self.fc12 = nn.Linear(16*n2,n3)\n",
        "        # self.fc13 = nn.Linear(16*n2,n3)\n",
        "\n",
        "        self.fc1 = nn.Linear(16*n2,n3)\n",
        "\n",
        "        # self.fc21 = nn.Linear(n3,1)\n",
        "        # self.fc22 = nn.Linear(n3,1)\n",
        "        # self.fc23 = nn.Linear(n3,1)\n",
        "        #\n",
        "        self.fc2 = nn.Linear(n3,1)\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        x1 = F.max_pool2d(self.conv11(x1), 2)\n",
        "        x2 = F.max_pool2d(self.conv12(x2), 2)\n",
        "        x3 = F.max_pool2d(self.conv13(x3), 2)\n",
        "\n",
        "        x1 = F.max_pool2d(self.conv21(x1), 2)\n",
        "        x2 = F.max_pool2d(self.conv22(x2), 2)  \n",
        "        x3 = F.max_pool2d(self.conv23(x3), 2) \n",
        "\n",
        "        x1 = x1.view(-1, self.num_flat_features(x1))\n",
        "        x2 = x2.view(-1, self.num_flat_features(x2))\n",
        "        x3 = x3.view(-1, self.num_flat_features(x3))\n",
        "\n",
        "        # x1 = F.leaky_relu(self.fc11(x1))\n",
        "        # x2 = F.leaky_relu(self.fc12(x2))\n",
        "        # x3 = F.leaky_relu(self.fc13(x3))\n",
        "\n",
        "        # x1 = torch.sigmoid(self.fc21(x1))\n",
        "        # x2 = torch.sigmoid(self.fc22(x2))\n",
        "        # x3 = torch.sigmoid(self.fc23(x3))\n",
        "\n",
        "        # return x1,x2,x3\n",
        "\n",
        "        x = x1+x2+x3\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "\n",
        "        return x#x1, x2, x3\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKARwwlw_xlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(x1, x2, x3):\n",
        "    D.zero_grad()\n",
        "    G.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real1 = x1#.view(-1, mnist_dim)\n",
        "    y_real1 = torch.ones(bs, 1)\n",
        "    x_real1, y_real1 = x_real1.to(device), y_real1.to(device)\n",
        "\n",
        "    x_real2 = x2 #x2.view(-1, mnist_dim), \n",
        "    y_real2 = torch.ones(bs, 1)\n",
        "    x_real2, y_real2 = x_real2.to(device), y_real2.to(device)\n",
        "\n",
        "    x_real3 = x3#.view(-1, mnist_dim)\n",
        "    y_real3 = torch.ones(bs, 1)\n",
        "    x_real3, y_real3 = x_real3.to(device), y_real3.to(device)\n",
        "\n",
        "    # D_output1, D_output2, D_output3 = D(x_real1,x_real2,x_real3)\n",
        "    D_output = D(x_real1,x_real2,x_real3)\n",
        "    # D_real_loss1 = (criterion(D_output1, y_real1) + criterion(D_output2, y_real2) + criterion(D_output3, y_real3))/3\n",
        "    D_real_loss1 = criterion(D_output, y_real1)\n",
        "    # train discriminator on fake\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "\n",
        "    x_fake1, x_fake2, x_fake3  = G(z)\n",
        "    y_fake1 = torch.zeros(bs, 1).to(device)\n",
        "    y_fake2 = torch.zeros(bs, 1).to(device)\n",
        "    y_fake3 = torch.zeros(bs, 1).to(device)\n",
        "\n",
        "    # D_output1, D_output2, D_output3 = D(x_fake1, x_fake2, x_fake3)\n",
        "    D_output = D(x_fake1, x_fake2, x_fake3)\n",
        "    # D_fake_loss1 = (criterion(D_output1, y_fake1) + criterion(D_output2, y_fake2) + criterion(D_output3, y_fake3))/3\n",
        "    D_fake_loss1 = criterion(D_output, y_fake1)\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = (D_real_loss1 + D_fake_loss1)/2 # + D_fake_loss2\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss#.data.item()\n",
        "\n",
        "\n",
        "def G_train():\n",
        "    G.zero_grad()\n",
        "    D.zero_grad()\n",
        "\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    y = torch.ones(bs, 1).to(device)\n",
        "\n",
        "    G_output1, G_output2, G_output3 = G(z)\n",
        "    # D_output1, D_output2, D_output3 = D(G_output1,G_output2,G_output3)\n",
        "    D_output = D(G_output1,G_output2,G_output3)\n",
        "\n",
        "    # G_loss = (criterion(D_output1, y) + criterion(D_output2, y) + criterion(D_output3, y))/3\n",
        "    G_loss = criterion(D_output,y)\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "    return G_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjWO1iosDu-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf results\n",
        "# !rm -rf saved_model\n",
        "# !mkdir results\n",
        "# !mkdir saved_model\n",
        "\n",
        "# !mv new_models/D_20.pth saved_model/D_20.pth\n",
        "# !mv new_models/G_20.pth saved_model/G_20.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZqCcIk_qMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "46e1f0e6-cbef-4d6f-c49c-0f6ddab0a7ac"
      },
      "source": [
        "# build network\n",
        "z_dim = 50\n",
        "bs = batch_size\n",
        "\n",
        "mnist_dim = train_dataset.X.shape[1]# * train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)\n",
        "\n",
        "# G.load_state_dict(torch.load('new_models/G_170.pth'))\n",
        "# D.load_state_dict(torch.load('new_models/D_170.pth'))\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv11): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv12): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv13): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv21): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv22): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv23): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wby08bzIjZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_optimizer = optim.Adam(G.parameters(), lr = 0.0005, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = 0.0005, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiX6OKXEf6J9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edf66721-2ad7-4af8-9300-648d0afce57a"
      },
      "source": [
        "# !mkdir new_models1\n",
        "# !mkdir results1\n",
        "!ls"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_train.csv      new_models   results\n",
            "mnist_train.csv.zip  new_models1  results1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZwTvQ-_2uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epoch = 300\n",
        "torch.manual_seed(7)\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x1, x2, x3) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x1,x2,x3))\n",
        "        G_losses.append(G_train())\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
        "    if epoch%2==0:\n",
        "        with torch.no_grad():\n",
        "            test_z = torch.randn(bs, z_dim).to(device)\n",
        "            g1, g2, g3 = G(test_z)\n",
        "            save_image(g1.view(g1.size(0), 1, 28, 28), 'results1/sample_%03d_1.png'%epoch)\n",
        "            save_image(g2.view(g2.size(0), 1, 28, 28), 'results1/sample_%03d_2.png'%epoch)\n",
        "            save_image(g3.view(g3.size(0), 1, 28, 28), 'results1/sample_%03d_3.png'%epoch)\n",
        "            torch.save(G.state_dict(), \"new_models1/G_%03d.pth\"%epoch)\n",
        "            torch.save(D.state_dict(), \"new_models1/D_%03d.pth\"%epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w75GtHD9Ac65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    generated = G(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), 'sample_{}.png'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_8cpu-5oqMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa906b3a-c971-45af-b61f-db67f5f61ea8"
      },
      "source": [
        "# !mkdir new_models\n",
        "i = 1\n",
        "print('results/sample_%02d_1.png'%i)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results/sample_01_1.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzFpLCCNCNKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(D.state_dict(), \"new_models/D_55.pth\")\n",
        "torch.save(G.state_dict(), \"new_models/G_55.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTJWOvBQycul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "def show(img):\n",
        "    npimg = img.detach().cpu().numpy()[0]\n",
        "    plt.imshow(npimg, interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNFmulSYC2y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "# from IPython.display import Image\n",
        "to_img = ToPILImage()\n",
        "\n",
        "# display tensor\n",
        "# a = t.Tensor(3, 64, 64).normal_()\n",
        "# to_img(a)\n",
        "# torch.manual_seed(10)\n",
        "test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "generated, generated_rotate = G(test_z)\n",
        "# generated.view(generated.size(0), 1, 28, 28)\n",
        "# to_img(generated.view(generated.size(0), 1, 28, 28)[1].cpu())\n",
        "show(generated.view(generated.size(0), 1, 28, 28)[3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv37PrG8xYa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def G_train(x,x_rotate):\n",
        "#     #=======================Train the generator 1=======================#\n",
        "#     G.zero_grad()\n",
        "\n",
        "#     z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "#     y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "#     G_output1 = G(z)\n",
        "#     D_output1 = D(G_output1)\n",
        "#     G_loss1 = criterion(D_output1, y)\n",
        "\n",
        "#     # gradient backprop & optimize ONLY G's parameters\n",
        "#     G_loss1.backward()\n",
        "#     G_optimizer.step()\n",
        "    \n",
        "#     #=======================Train the generator 2=======================#\n",
        "    \n",
        "#     G_rotate.zero_grad()\n",
        "\n",
        "#     # z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "#     # y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "#     G_output2 = G_rotate(z)\n",
        "#     D_output2 = D_rotate(G_output2)\n",
        "#     G_loss2 = criterion(D_output2, y)\n",
        "\n",
        "#     # gradient backprop & optimize ONLY G's parameters\n",
        "#     G_loss2.backward()\n",
        "#     G_rotate_optimizer.step()\n",
        "\n",
        "\n",
        "#     return G_loss1.data.item() + G_loss2.data.item()\n",
        "\n",
        "\n",
        "\n",
        "# def D_train(x1, x2):\n",
        "#     #=======================Train the discriminator 1=======================#\n",
        "#     D.zero_grad()\n",
        "\n",
        "#     # train discriminator on real\n",
        "#     x_real1, y_real1 = x1.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "#     x_real1, y_real1 = Variable(x_real1.to(device)), Variable(y_real1.to(device))\n",
        "\n",
        "#     D_output1 = D(x_real1)\n",
        "#     D_real_loss1 = criterion(D_output1, y_real1)\n",
        "#     D_real_score1 = D_output1\n",
        "\n",
        "#     # train discriminator on facke\n",
        "#     z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "#     x_fake1, y_fake1 = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "#     D_output1 = D(x_fake1)\n",
        "#     D_fake_loss1 = criterion(D_output1, y_fake1)\n",
        "#     D_fake_score1 = D_output1\n",
        "\n",
        "#     # gradient backprop & optimize ONLY D's parameters\n",
        "#     D_loss1 = D_real_loss1 + D_fake_loss1\n",
        "#     D_loss1.backward()\n",
        "#     D_optimizer.step()\n",
        "\n",
        "#     #=======================Train the discriminator 2=======================# \n",
        "#     D_rotate.zero_grad()\n",
        "\n",
        "#     x_real2, y_real2 = x2.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "#     x_real2, y_real2 = Variable(x_real2.to(device)), Variable(y_real2.to(device))\n",
        "\n",
        "#     D_output2 = D_rotate(x_real2)\n",
        "#     D_real_loss2 = criterion(D_output2, y_real2)\n",
        "#     D_real_score2 = D_output2\n",
        "\n",
        "#     # train discriminator on facke\n",
        "#     # z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "#     x_fake2, y_fake2 = G_rotate(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "#     D_output2 = D_rotate(x_fake2)\n",
        "#     D_fake_loss2 = criterion(D_output2, y_fake2)\n",
        "#     D_fake_score2 = D_output2\n",
        "\n",
        "#     # gradient backprop & optimize ONLY D's parameters\n",
        "#     D_loss2 = D_real_loss2 + D_fake_loss2\n",
        "#     D_loss2.backward()\n",
        "#     D_rotate_optimizer.step()\n",
        "        \n",
        "#     return  D_loss1.data.item()# + D_loss2.data.item()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmGoUKCN_gv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bs = 100\n",
        "\n",
        "# # MNIST Dataset\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor()])#,\n",
        "#     # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "# transform_rotate = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     ])#,\n",
        "#     # transforms.RandomRotation((90,90))])\n",
        "\n",
        "\n",
        "# train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "# test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "# train_dataset_rotate = datasets.MNIST(root='./mnist_data/', train=True, transform=transform_rotate, download=True)\n",
        "# test_dataset_rotate = datasets.MNIST(root='./mnist_data/', train=False, transform=transform_rotate, download=False)\n",
        "\n",
        "# # Data Loader (Input Pipeline)\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "# train_loader_rotate = torch.utils.data.DataLoader(dataset=train_dataset_rotate, batch_size=bs, shuffle=True)\n",
        "# test_loader_rotate = torch.utils.data.DataLoader(dataset=test_dataset_rotate, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}